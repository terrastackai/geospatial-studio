{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Geospatial Studio\n",
    "\n",
    "This notebook walks you through the essential workflows for using the Geospatial Studio:\n",
    "\n",
    "1. **API Setup** - Configure your environment\n",
    "2. **Onboard Sandbox Models** - Set up placeholder models\n",
    "3. **Load Existing Inferences** - Import example outputs\n",
    "4. **Run Inference** - Use pre-tuned models\n",
    "5. **Fine-tune Models** - Train models on your data\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Geospatial Studio deployed and running\n",
    "- Access to Studio UI at `https://localhost:4180`\n",
    "- Python environment with required packages\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: API Key Setup\n",
    "\n",
    "### Generate API Key\n",
    "\n",
    "1. Navigate to [https://localhost:4180](https://localhost:4180)\n",
    "2. Log in with default credentials:\n",
    "   - Username: `testuser`\n",
    "   - Password: `testpass123`\n",
    "3. Click **\"Manage your API keys\"** link\n",
    "4. Generate a new API key and copy it\n",
    "\n",
    "\n",
    "### Configure Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key (paste the key you generated)\n",
    "import os\n",
    "\n",
    "os.environ['STUDIO_API_KEY'] = \"<paste your API key here>\"\n",
    "os.environ['UI_ROUTE_URL'] = \"https://localhost:4180\"\n",
    "\n",
    "# Verify the variables are set\n",
    "print(f\"API Key: {os.environ['STUDIO_API_KEY'][:10]}...\")\n",
    "print(f\"UI URL: {os.environ['UI_ROUTE_URL']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Onboard Sandbox Models\n",
    "\n",
    "Sandbox models are placeholder pipelines useful for:\n",
    "- Onboarding existing inferences\n",
    "- Testing tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./deployment-scripts/add-sandbox-models.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Onboard Existing Inference (Example Data)\n",
    "\n",
    "Load a pre-computed inference to explore the platform.\n",
    "\n",
    "This will:\n",
    "1. Start a pipeline to pull the data\n",
    "2. Set it up in the platform\n",
    "3. Make it visible in the Inferences page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Run the populate script and select \"AGB Data - Karen, Nairobi, Kenya\"\n",
    "python populate-studio/populate-studio.py inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After running the above:**\n",
    "- Navigate to the **Inferences** page in the UI\n",
    "- You should see the example you just added\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Onboard a Pre-Tuned Model and Run Inference\n",
    "\n",
    "### 4.1 Onboard Tuning Task Templates\n",
    "\n",
    "Templates make it easier to configure tuning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Select: 1. Segmentation - Generic template v1 and v2 models: Segmentation\n",
    "python populate-studio/populate-studio.py templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Onboard a Tuned Model\n",
    "\n",
    "We'll onboard the `prithvi-eo-flood` model from a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Select: prithvi-eo-flood - prithvi-eo-flood\n",
    "python populate-studio/populate-studio.py tunes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the UI:**\n",
    "- Navigate to **Models/Tunes** page\n",
    "- Wait for the download to complete\n",
    "- Copy the `tune_id` for the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Run Inference with the Tuned Model\n",
    "\n",
    "Now we'll run inference over a specific spatial and temporal domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# IMPORTANT: Replace with your tune_id from the UI\n",
    "tune_id = \"<paste tune_id here>\"\n",
    "\n",
    "# Define the inference payload\n",
    "payload = {\n",
    "    \"model_display_name\": \"geofm-sandbox-models\",\n",
    "    \"location\": \"Dakhin Petbaha, Raha, Nagaon, Assam, India\",\n",
    "    \"description\": \"Flood Assam local with sentinel aws\",\n",
    "    \"spatial_domain\": {\n",
    "        \"bbox\": [\n",
    "            [92.703396, 26.247896, 92.748087, 26.267903]\n",
    "        ],\n",
    "        \"urls\": [],\n",
    "        \"tiles\": [],\n",
    "        \"polygons\": []\n",
    "    },\n",
    "    \"temporal_domain\": [\n",
    "        \"2024-07-25_2024-07-28\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Submit the inference request\n",
    "url = f\"{os.environ['UI_ROUTE_URL']}/studio-gateway/v2/tunes/{tune_id}/try-out\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-API-Key\": os.environ['STUDIO_API_KEY']\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers, verify=False)\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Monitor Progress:**\n",
    "- Go to the **Inferences** page in the UI\n",
    "- Watch the job progress\n",
    "- Access results via [MinIO UI](https://localhost:9001)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fine-Tune a Model from Your Dataset\n",
    "\n",
    "### 5.1 Onboard a Tuning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Select: \"Wildfire burn scars\"\n",
    "python populate-studio/populate-studio.py datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the UI:**\n",
    "- Navigate to **Datasets** page\n",
    "- Dataset will show as \"Pending\" initially\n",
    "- Wait for it to complete (a few minutes)\n",
    "- Copy the `dataset_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Onboard Backbone Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Select: \"Prithvi_EO_V2_300M\"\n",
    "python populate-studio/populate-studio.py backbones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy the `base_model_id` from the response or UI.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Onboard Tuning Templates (if not done already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Select: 1. Segmentation - Generic template v1 and v2 models: Segmentation\n",
    "python populate-studio/populate-studio.py templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy the `tune_template_id` from the response or UI.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Submit Fine-Tuning Job\n",
    "\n",
    "⚠️ **Note for Mac Users:** If you're on a Mac without NVIDIA GPUs, see the [Mac GPU Tuning](#mac-gpu-tuning) section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# IMPORTANT: Replace these IDs with your actual IDs from previous steps\n",
    "dataset_id = \"<paste dataset_id here>\"\n",
    "base_model_id = \"<paste base_model_id here>\"\n",
    "tune_template_id = \"<paste tune_template_id here>\"\n",
    "\n",
    "# Define the tuning payload\n",
    "payload = {\n",
    "    \"name\": \"burn-scars-demo\",\n",
    "    \"description\": \"Segmentation\",\n",
    "    \"dataset_id\": dataset_id,\n",
    "    \"base_model_id\": base_model_id,\n",
    "    \"tune_template_id\": tune_template_id,\n",
    "    \"train_options\": {\n",
    "        \"model_input_data_spec\": [\n",
    "            {\n",
    "                \"bands\": [\n",
    "                    {\"index\": \"0\", \"band_name\": \"Blue\", \"scaling_factor\": \"0.0001\", \"RGB_band\": \"B\"},\n",
    "                    {\"index\": \"1\", \"band_name\": \"Green\", \"scaling_factor\": \"0.0001\", \"RGB_band\": \"G\"},\n",
    "                    {\"index\": \"2\", \"band_name\": \"Red\", \"scaling_factor\": \"0.0001\", \"RGB_band\": \"R\"},\n",
    "                    {\"index\": \"3\", \"band_name\": \"NIR_Narrow\", \"scaling_factor\": \"0.0001\"},\n",
    "                    {\"index\": \"4\", \"band_name\": \"SWIR1\", \"scaling_factor\": \"0.0001\"},\n",
    "                    {\"index\": \"5\", \"band_name\": \"SWIR2\", \"scaling_factor\": \"0.0001\"}\n",
    "                ],\n",
    "                \"connector\": \"sentinelhub\",\n",
    "                \"collection\": \"hls_l30\",\n",
    "                \"file_suffix\": \"_merged.tif\",\n",
    "                \"modality_tag\": \"HLS_L30\"\n",
    "            }\n",
    "        ],\n",
    "        \"label_categories\": [\n",
    "            {\"id\": \"-1\", \"name\": \"Ignore\", \"color\": \"#000000\", \"opacity\": 0, \"weight\": None},\n",
    "            {\"id\": \"0\", \"name\": \"No data\", \"color\": \"#000000\", \"opacity\": 0, \"weight\": None},\n",
    "            {\"id\": \"1\", \"name\": \"Fire Scar\", \"color\": \"#ab4f4f\", \"opacity\": 1, \"weight\": None}\n",
    "        ]\n",
    "    },\n",
    "    \"model_parameters\": {\n",
    "        \"data\": {\"check_stackability\": \"false\"},\n",
    "        \"runner\": {\"max_epochs\": \"5\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Submit the tuning job\n",
    "url = f\"{os.environ['UI_ROUTE_URL']}/studio-gateway/v2/submit-tune\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-API-Key\": os.environ['STUDIO_API_KEY']\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers, verify=False)\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n",
    "\n",
    "# Save the tune_id for later\n",
    "if response.status_code == 200:\n",
    "    new_tune_id = response.json().get('tune_id')\n",
    "    print(f\"\\n✅ Tuning job submitted! Tune ID: {new_tune_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Monitor Training:**\n",
    "- Open [MLflow UI](https://localhost:5000)\n",
    "- Track training progress and metrics\n",
    "- Wait for training to complete (depends on epochs and data size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Run Inference with Your Tuned Model\n",
    "\n",
    "After training completes, run inference with your newly tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# IMPORTANT: Replace with your new tune_id from the training job\n",
    "tune_id = \"<paste new tune_id here>\"\n",
    "\n",
    "# Expanded inference payload with full configuration\n",
    "payload = {\n",
    "    \"model_display_name\": \"geofm-sandbox-models\",\n",
    "    \"location\": \"Red Bluff, California, United States\",\n",
    "    \"description\": \"Park Fire Aug 2024\",\n",
    "    \"spatial_domain\": {\n",
    "        \"bbox\": [],\n",
    "        \"urls\": [\n",
    "            \"https://geospatial-studio-example-data.s3.us-east.cloud-object-storage.appdomain.cloud/examples-for-inference/park_fire_scaled.tif\"\n",
    "        ],\n",
    "        \"tiles\": [],\n",
    "        \"polygons\": []\n",
    "    },\n",
    "    \"temporal_domain\": [\"2024-08-12\"],\n",
    "    \"pipeline_steps\": [\n",
    "        {\"status\": \"READY\", \"process_id\": \"url-connector\", \"step_number\": 0},\n",
    "        {\"status\": \"WAITING\", \"process_id\": \"terratorch-inference\", \"step_number\": 1},\n",
    "        {\"status\": \"WAITING\", \"process_id\": \"postprocess-generic\", \"step_number\": 2},\n",
    "        {\"status\": \"WAITING\", \"process_id\": \"push-to-geoserver\", \"step_number\": 3}\n",
    "    ],\n",
    "    \"post_processing\": {\n",
    "        \"cloud_masking\": \"False\",\n",
    "        \"ocean_masking\": \"False\",\n",
    "        \"snow_ice_masking\": None,\n",
    "        \"permanent_water_masking\": \"False\"\n",
    "    },\n",
    "    \"model_input_data_spec\": [\n",
    "        {\n",
    "            \"bands\": [\n",
    "                {\"index\": \"0\", \"RGB_band\": \"B\", \"band_name\": \"Blue\", \"scaling_factor\": \"0.0001\"},\n",
    "                {\"index\": \"1\", \"RGB_band\": \"G\", \"band_name\": \"Green\", \"scaling_factor\": \"0.0001\"},\n",
    "                {\"index\": \"2\", \"RGB_band\": \"R\", \"band_name\": \"Red\", \"scaling_factor\": \"0.0001\"},\n",
    "                {\"index\": \"3\", \"band_name\": \"NIR_Narrow\", \"scaling_factor\": \"0.0001\"},\n",
    "                {\"index\": \"4\", \"band_name\": \"SWIR1\", \"scaling_factor\": \"0.0001\"},\n",
    "                {\"index\": \"5\", \"band_name\": \"SWIR2\", \"scaling_factor\": \"0.0001\"}\n",
    "            ],\n",
    "            \"connector\": \"sentinelhub\",\n",
    "            \"collection\": \"hls_l30\",\n",
    "            \"file_suffix\": \"_merged.tif\",\n",
    "            \"modality_tag\": \"HLS_L30\"\n",
    "        }\n",
    "    ],\n",
    "    \"geoserver_push\": [\n",
    "        {\n",
    "            \"z_index\": 0,\n",
    "            \"workspace\": \"geofm\",\n",
    "            \"layer_name\": \"input_rgb\",\n",
    "            \"display_name\": \"Input image (RGB)\",\n",
    "            \"filepath_key\": \"model_input_original_image_rgb\",\n",
    "            \"visible_by_default\": \"True\",\n",
    "            \"geoserver_style\": {\n",
    "                \"rgb\": [\n",
    "                    {\"label\": \"RedChannel\", \"channel\": 1, \"maxValue\": 255, \"minValue\": 0},\n",
    "                    {\"label\": \"GreenChannel\", \"channel\": 2, \"maxValue\": 255, \"minValue\": 0},\n",
    "                    {\"label\": \"BlueChannel\", \"channel\": 3, \"maxValue\": 255, \"minValue\": 0}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"z_index\": 1,\n",
    "            \"workspace\": \"geofm\",\n",
    "            \"layer_name\": \"pred\",\n",
    "            \"display_name\": \"Model prediction\",\n",
    "            \"filepath_key\": \"model_output_image\",\n",
    "            \"visible_by_default\": \"True\",\n",
    "            \"geoserver_style\": {\n",
    "                \"segmentation\": [\n",
    "                    {\"color\": \"#000000\", \"label\": \"ignore\", \"opacity\": 0, \"quantity\": \"-1\"},\n",
    "                    {\"color\": \"#000000\", \"label\": \"no-data\", \"opacity\": 0, \"quantity\": \"0\"},\n",
    "                    {\"color\": \"#ab4f4f\", \"label\": \"fire-scar\", \"opacity\": 1, \"quantity\": \"1\"}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Submit inference\n",
    "url = f\"{os.environ['UI_ROUTE_URL']}/studio-gateway/v2/tunes/{tune_id}/try-out\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-API-Key\": os.environ['STUDIO_API_KEY']\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers, verify=False)\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response: {json.dumps(response.json(), indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View Results:**\n",
    "- Navigate to **Inferences** page in UI\n",
    "- Monitor job progress\n",
    "- View results in GeoServer\n",
    "- Access files via [MinIO UI](https://localhost:9001)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mac GPU Tuning (Alternative Workflow)\n",
    "\n",
    "For Mac users without NVIDIA GPUs, you can prepare the tuning configuration in the Studio and run it locally with TerraTorch.\n",
    "\n",
    "### Prepare Tuning Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# IMPORTANT: Replace these IDs with your actual IDs\n",
    "dataset_id = \"<paste dataset_id here>\"\n",
    "base_model_id = \"<paste base_model_id here>\"\n",
    "tune_template_id = \"<paste tune_template_id here>\"\n",
    "\n",
    "payload = {\n",
    "    \"name\": \"burn-scars-demo\",\n",
    "    \"description\": \"Segmentation\",\n",
    "    \"dataset_id\": dataset_id,\n",
    "    \"base_model_id\": base_model_id,\n",
    "    \"tune_template_id\": tune_template_id,\n",
    "    \"model_parameters\": {\n",
    "        \"runner\": {\"max_epochs\": \"10\"},\n",
    "        \"optimizer\": {\"lr\": 6e-05, \"type\": \"AdamW\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Get dry-run config\n",
    "url = f\"{os.environ['UI_ROUTE_URL']}/studio-gateway/v2/submit-tune/dry-run\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-API-Key\": os.environ['STUDIO_API_KEY']\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers, verify=False)\n",
    "\n",
    "# Save config to file\n",
    "with open('config.yaml', 'w') as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "print(\"✅ Config saved to config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localize Config Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./deployment-scripts/localize_config.sh config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "terratorch fit -c config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Tuned Model Back to Studio\n",
    "\n",
    "After training completes, upload your checkpoint back to the Studio.Once its complete, you should see the it in the UI under the tunes/models page.\n",
    "\n",
    "*(API endpoint for upload to be added)*\n",
    "*(API call to try out inferenfe)*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
